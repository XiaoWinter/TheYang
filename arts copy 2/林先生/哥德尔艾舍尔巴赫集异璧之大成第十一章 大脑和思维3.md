<h2>1、符号——是软件还是硬件？</h2><p data-pid="k1z2dMax">由于在每个人的大脑中都存放着数量众多甚至仍在不断增加的符号，你可能会问是否有一天大脑终于会饱和——那时新符号将不再有容身之处。推测起来，这种情况的出现条件是符号不彼此重叠</p><p data-pid="jyhv52PE">但是，这并不是大脑功能的符号模型的一个必然性质。事实上，符号间的重叠和缠结很可能已成惯例，因此每个神经原也许会成为上百个符号的功能部件，而远不是只属于一个符号。这有点让人摸不着头脑了，因为如果真是这样，那不是很容易变成每个神经原都是任何符号的一部分了吗？若是如此，无论什么样的符号定位都不可能存在——每个符号都将对应于整个大脑。</p><p><br></p><h2>2、智能的可抽取性</h2><p data-pid="XkWjqVHJ">为阐明大脑中发生的思维过程，我们还剩下两个基本问题。一个是解释低层次的神经发射通讯是如何导致高层次的符号激活通讯的，另一个是自足地解释高层次的符号激活通讯——建立一个不涉及低层神经事件的理论。</p><p data-pid="lCjS7hCH">如果后者是可能的——这是目前进行的所有人工智能研究的基础中的一个关键假设——那么智能就可能实现于不同于大脑的其它硬件上。那将表明智能是一种可以从它所在的硬件中“抽取”出来的性质——换句话说，智能将是一种软件性质。这将意味着意识和智能这一现象的确和大多数其它复杂的自然现象一样是高层次的：它们有自身的高层规律，这些规律依赖于低层，但又可以从低层中“抽取”出来。</p><p data-pid="KEUxxm8p">这里我们要回到蚁群那神秘的集体行为。它们能建造巨大而复杂的蚁穴，尽管事实上一只?蚁的脑中仅有约十万个神经原，几乎不可能载有关于蚁穴结构的任何信息。那么蚁穴是如何构造的呢？信息来自何处？它们一定是以某种方式散布在蚁群中</p><p><br></p><h2>3、单个符号能否被隔离出来？</h2><p data-pid="KLlzdB6V">是否有可能在与所有其它符号相隔离的条件下唤醒一个符号？大概不行。正好象世界上的对象总是存在于其它对象组成的环境中一样，符号也总是联系于其它符号所组成的星云。这并不一定意味着符号不可能摆脱其它符号的纠缠。打一个简单的比方：雄性和雌性在一个物种中总是同时出现的，它们的作用是完全交织在一起的，但这并不是说雄雌没办法区分。</p><p data-pid="lq0552Fe">类似地，相互之间存在多重联系的符号也是交织在一起，但又应当能彼此区分的。这可能涉及到识别神经网络，即一个网络及其激活方式——或者也可能是某种完全不同的东西。</p><p><br></p><h2>4、昆虫的符号</h2><p data-pid="dJjCuyqk">我们从类中产生例和从例中产生类的能力存在于智能的基础之中，它是人的思维与其它动物的思维过程的一个重要区别。并非我曾属于其它物种，从而得到了第一手资料，能说明象它们那样思维会是什么感觉——但外部迹象表明，<b>其它物种都不能象我们这样形成一般概念或想象假设的世界——即现存世界的各种变种</b>，借此我们可以选择通往未来的道路。</p><p><br></p><h2>5、类符号和假想世界</h2><p data-pid="GWiLh5fN">通常符号所扮演的角色是同构于似乎能发生的事件，但有时激活的符号也表示不可能出现的情况——例如咝咝作响的手表，乐队中的大号在下蛋，等等。可能事件和不可能事件之间的界线是极其模糊的。当我们想象一个假设的事件时，我们使某些符号进入活跃状态——根据它们相互作用的情况（这大概反映在我们继续思维时的舒适程度中），我们说事件“可能”或“不可能”发生。因此所谓“可能”和“不可能”是非常主观的。</p><p data-pid="07yWy0Jm">这反映了我们的精神结构有很大一部分是同样的——但存在一个边界区域，在那里，我愿意接受哪一种假设世界，这是带有鲜明的主观色彩的。人们认为哪种假想事件可能发生，哪种不可能发生，对这一问题的深入研究可能使我们对人们思维中的符号触发模式有进一步的理解。</p><p><br></p><h2>6、直观的物理定律</h2><p data-pid="gf6HvV-G">当电话打完之后，你已经建立了关于一个场景的精制的心理模型，在此模型中所有对象都遵从物理定律。这意味着物理定律本身一定是被隐含地表示在符号的触发模式之中。当然，所谓“物理定律”在这里并不是指“物理学家所陈述的物理学中的定律”，而是指那种直观的、组块化的规律。为了活下去，我们每个人头脑中都一定有这样的规律。</p><p data-pid="hWVxmUni">言而喻，我们大脑中所具有的组块化定律不仅仅是关于非生物的活动的，也有关于植物、动物、人和社会的活动的——即组块化的生物学、心理学、社会学定律，如此等等。所有这些对象的内部表示都具有组块化模型的必然特征：<b>为保证简单性而牺牲确定性</b>。</p><p data-pid="TNrQ2AoR">我们对现实的表示的最终结果仅仅是可以预测抽象行为空间的某些局部结果的可能性——而不是以物理学的精确度预测所有的东西。</p><p><br></p><h2>7、过程性知识和描述性知识</h2><p data-pid="gtlx3zhO">在人工智能研究中，对过程性知识和描述性知识进行了区分。一条知识被称为“描述性”的，条件是它是被显式存贮的，因此除了程序员外，程序也可以“读”它，就象它是一本百科全书或一本年鉴。</p><p data-pid="Ueg_lejN">与此相反，“过程性”知识不是以事实的形式编码的，而仅仅以程序的形式编码。一个程序员可以看着它说，“我看到了因为这里有这些过程，程序‘知道’如何写中文句子”——但程序自身可能并没有明确意识到它是如何写这些句子的。因此过程性知识通常零散地分布在各处，你对它们无法进行提取和检索。它是一个程序的工作过程的全局性结果，而不是局部的细节。</p><p data-pid="-fBvY5cB">大脑是怎么知道一条知识是否是以描述性的方式存贮的？例如，假设有人问你：“广州的人口总数是多少？”五百万这个数目会以某种方式出现在你的脑海里，而用不着你去琢磨：“我怎样才能去把他们都数一遍呢？”现在假设我问你：“你的房间里有几把椅子？”在这里，相反的情况出现了——你不会试图把答案从脑中的资料库里挖出来，而是立即回屋去数一遍，或是在脑海中构造你的屋子，然后在想象的屋子里清点椅子的数目。这两个问题是同一类的——“有多少？”——但一个问题致使一条描述性的知识被取出，而另一个致使一个寻找答案的过程化方法被调用。</p><p><br></p><h2>8、视觉表象</h2><p data-pid="TT-e9CL6">意识最值得注意、也最难以描述的性质之一就是视觉表象。我们是怎样构造一个视觉表象，以表示我们的房间、或一条喧闹的山间溪流、或一个桔子的？</p><p data-pid="CLxzU102">表象有可能是基于我们对运动行为的抑制能力的。这就是说，一旦你想象出一只桔子，在你的皮层中可能产生一系列命令，如拿起它、闻闻它、查看它、等等。很明显这些命令不能被执行，因为实际上并没有桔子。但它们可以沿通常的渠道被送至小脑或脑的其它子器官，直到一个“精神龙头”在某临界点被拧紧，阻止它们的实际执行。这个表象可能具有或多或少的生动性和似真性</p><p></p>